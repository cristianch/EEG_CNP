
@article{martinez_pca_2001,
	title = {{PCA} versus {LDA}},
	volume = {23},
	issn = {1939-3539},
	doi = {10.1109/34.908974},
	abstract = {In the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (linear discriminant analysis) are superior to those based on PCA (principal components analysis). In this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then, by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Martinez, A.M. and Kak, A.C.},
	month = feb,
	year = {2001},
	keywords = {Databases, Face recognition, LDA, Linear discriminant analysis, Mobile robots, Object recognition, PCA, Pattern recognition, Principal component analysis, Service robots, Switches, Training data, appearance-based paradigm, face database, image recognition, linear discriminant analysis, object recognition, principal component analysis, principal components analysis},
	pages = {228--233}
}

@article{rish_empirical_2001,
	title = {An empirical study of the naive {Bayes} classiﬁer},
	abstract = {The naive Bayes classiﬁer greatly simplify learning by assuming that features are independent given class. Although independence is generally a poor assumption, in practice naive Bayes often competes well with more sophisticated classiﬁers.},
	language = {en},
	author = {Rish, I},
	year = {2001},
	pages = {6}
}

@inproceedings{chen_automated_2012,
	address = {Maui, Hawaii, USA},
	title = {Automated feature weighting in naive bayes for high-dimensional data classification},
	isbn = {978-1-4503-1156-4},
	url = {http://dl.acm.org/citation.cfm?doid=2396761.2398426},
	doi = {10.1145/2396761.2398426},
	abstract = {Naive Bayes (NB for short) is one of the popular methods for supervised classiﬁcation in a knowledge management system. Currently, in many real-world applications, highdimensional data pose a major challenge to conventional NB classiﬁers, due to noisy or redundant features and local relevance of these features to classes. In this paper, an automated feature weighting solution is proposed to result in a NB method eﬀective in dealing with high-dimensional data. We ﬁrst propose a locally weighted probability model, for Bayesian modeling in high-dimensional spaces, to implement a soft feature selection scheme. Then we propose an optimization algorithm to ﬁnd the weights in linear time complexity, based on the Logitnormal priori distribution and the Maximum a Posteriori principle. Experimental studies show the eﬀectiveness and suitability of the proposed model for high-dimensional data classiﬁcation.},
	language = {en},
	urldate = {2019-11-26},
	booktitle = {Proceedings of the 21st {ACM} international conference on {Information} and knowledge management - {CIKM} '12},
	publisher = {ACM Press},
	author = {Chen, Lifei and Wang, Shengrui},
	year = {2012},
	pages = {1243}
}

@inproceedings{read_developing_2014,
	title = {Developing {Entrepreneurial} {Skills} in {IT} {Courses}: {The} {Role} of {Agile} {Software} {Development} {Practices} in {Producing} {Successful} {Student} {Initiated} {Products}},
	shorttitle = {Developing {Entrepreneurial} {Skills} in {IT} {Courses}},
	doi = {10.1109/HICSS.2014.34},
	abstract = {Universities are under increasing pressure to provide real world experience to students. Entrepreneurial courses are prevalent in business schools and have been shown to develop entrepreneurial skills. Entrepreneurial skills are equally important in the development of IT innovations. The research in this area of education is not as prevalent. We argue that Agile Software development methods, along with other key course characteristics enable students to learn entrepreneurial skills related to IT product development and do so in an environment where innovation can flourish. We present some preliminary data, which demonstrates some success in the course in developing entrepreneurial skills, with a particular focus on the use of Agile Development and mentoring methods in developing those skills.},
	booktitle = {2014 47th {Hawaii} {International} {Conference} on {System} {Sciences}},
	author = {Read, Aaron and Derrick, Douglas C. and Ligon, Gina S.},
	month = jan,
	year = {2014},
	note = {ISSN: 1530-1605},
	keywords = {Educational institutions, IT courses, Innovation management, Product development, Software, Technological innovation, agile software development, computer science education, educational courses, educational institutions, entrepreneurial courses, entrepreneurial skills, information technology, innovation, innovation management, software prototyping, student initiated products, universities},
	pages = {201--209}
}

@book{sharp_agile_2016,
	title = {Agile {Processes}, in {Software} {Engineering}, and {Extreme} {Programming}: 17th {International} {Conference}, {XP} 2016, {Edinburgh}, {UK}, {May} 24-27, 2016, {Proceedings}},
	isbn = {978-3-319-33515-5},
	shorttitle = {Agile {Processes}, in {Software} {Engineering}, and {Extreme} {Programming}},
	abstract = {This book contains the refereed proceedings of the 17th International Conference on Agile Software Development, XP 2016, held in Edinburgh, UK, in May 2016.While agile development has already become mainstream in industry, this field is still constantly evolving and continues to spur an enormous interest both in industry and academia. To this end, the XP conference attracts a large number of software practitioners and researchers, providing a rare opportunity for interaction between the two communities. The 14 full papers accepted for XP 2016 were selected from 42 submissions. Additionally, 11 experience reports (from 25 submissions) 5 empirical studies (out of 12 submitted) and 5 doctoral papers (from 6 papers submitted) were selected, and in each case the authors were shepherded by an experienced researcher. Generally, all of the submitted papers went through a rigorous peer-review process.},
	language = {en},
	publisher = {Springer},
	author = {Sharp, Helen and Hall, Tracy},
	month = may,
	year = {2016},
	note = {Google-Books-ID: RtlCDwAAQBAJ},
	keywords = {Business \& Economics / Business Mathematics, Business \& Economics / Information Management, Business \& Economics / Management, Computers / Enterprise Applications / Business Intelligence Tools, Computers / Enterprise Applications / General, Computers / Software Development \& Engineering / General, Computers / Systems Architecture / General}
}

@article{lalsing_people_2012,
	title = {People {Factors} in {Agile} {Software} {Development} and {Project} {Management}},
	volume = {3},
	issn = {09762221},
	url = {http://www.airccse.org/journal/ijsea/papers/3112ijsea09.pdf},
	doi = {10.5121/ijsea.2012.3109},
	abstract = {With the increasing popularity of Agile Methods, many software organisations are moving away from traditional methods to adopt Agile development methodologies. Instead of being predictive, Agile is rather adaptive and people-focussed. It advocates a small and collaborative team that work closely together. But team size is a factor that is in turn constrained by people factors. When implementing Agile, these key factors are often overlooked. This study aims at identifying the underlying people factors to consider when adopting Agile for a team to be effective. The method used is the study of three different sized Agile teams developing products based on the same technologies and using Scrum. Both objective and subjective measures were used and the results are supported by a survey. The results clearly show that for agile methodologies to work well, it is crucial to select the right people for the right team.},
	language = {en},
	number = {1},
	urldate = {2019-11-25},
	journal = {International Journal of Software Engineering \& Applications},
	author = {Lalsing, Vikash},
	month = jan,
	year = {2012},
	pages = {117--137}
}

@article{gallardo_transferable_2017,
	title = {{TRANSFERABLE} {CLASSIFIERS} {FOR} {EEG} {BASED} {DETECTION} {OF} {NEUROPATHIC} {PAIN} {IN} {PEOPLE} {WITH} {SPINAL} {CORD} {INJURY}},
	language = {en},
	author = {Gallardo, Vicente Jose Ferrer and Vuckovic, Aleksandra},
	month = aug,
	year = {2017}
}

@misc{gandhi_support_2018,
	title = {Support {Vector} {Machine} — {Introduction} to {Machine} {Learning} {Algorithms}},
	url = {https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47},
	abstract = {SVM model from scratch},
	language = {en},
	urldate = {2019-11-24},
	journal = {Medium},
	author = {Gandhi, Rohith},
	month = jul,
	year = {2018}
}

@inproceedings{lang_nonlinear_1995,
	title = {Nonlinear processing of a shift-invariant discrete wavelet transform ({DWT}) for noise reduction},
	volume = {2491},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2491/0000/Nonlinear-processing-of-a-shift-invariant-discrete-wavelet-transform-DWT/10.1117/12.205427.short},
	doi = {10.1117/12.205427},
	abstract = {A novel approach for noise reduction is presented. Similar to Donoho, we employ thresholding in some wavelet transform domain but use a nondecimated and consequently redundant wavelet transform instead of the usual orthogonal one. Another difference is the shift invariance as opposed to the traditional orthogonal wavelet transform. We show that this new approach can be interpreted as a repeated application of Donoho's original method. The main feature is, however, a dramatically improved noise reduction compared to Donoho's approach, both in terms of the l{\textless}SUB{\textgreater}2{\textless}/SUB{\textgreater} error and visually, for a large class of signals. This is shown by theoretical and experimental results, including synthetic aperture radar (SAR) images.},
	urldate = {2019-11-12},
	booktitle = {Wavelet {Applications} {II}},
	publisher = {International Society for Optics and Photonics},
	author = {Lang, Markus and Guo, Haitao and Odegard, Jan Erik and Burrus, C. Sidney and Jr, Raymond O. Wells},
	month = apr,
	year = {1995},
	pages = {640--651}
}

@article{kesic_application_2016,
	title = {Application of {Higuchi}'s fractal dimension from basic to clinical neurophysiology: {A} review},
	volume = {133},
	shorttitle = {Application of {Higuchi}'s fractal dimension from basic to clinical neurophysiology},
	doi = {10.1016/j.cmpb.2016.05.014},
	abstract = {Background and objective: 
For more than 20 years, Higuchi's fractal dimension (HFD), as a nonlinear method, has occupied an important place in the analysis of biological signals. The use of HFD has evolved from EEG and single neuron activity analysis to the most recent application in automated assessments of different clinical conditions. Our objective is to provide an updated review of the HFD method applied in basic and clinical neurophysiological research.

Methods:
This article summarizes and critically reviews a broad literature and major findings concerning the applications of HFD for measuring the complexity of neuronal activity during different neurophysiological conditions. The source of information used in this review comes from the PubMed, Scopus, Google Scholar and IEEE Xplore Digital Library databases.

Results:
The review process substantiated the significance, advantages and shortcomings of HFD application within all key areas of basic and clinical neurophysiology. Therefore, the paper discusses HFD application alone, combined with other linear or nonlinear measures, or as a part of automated methods for analyzing neurophysiological signals.

Conclusions:
The speed, accuracy and cost of applying the HFD method for research and medical diagnosis make it stand out from the widely used linear methods. However, only a combination of HFD with other nonlinear methods ensures reliable and accurate analysis of a wide range of neurophysiological signals.},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Kesić, Srdjan and Spasic, Sladjana},
	month = may,
	year = {2016}
}

@article{higuchi_approach_1988,
	title = {Approach to an irregular time series on the basis of the fractal theory},
	volume = {31},
	issn = {0167-2789},
	url = {http://www.sciencedirect.com/science/article/pii/0167278988900814},
	doi = {10.1016/0167-2789(88)90081-4},
	abstract = {We present a technique to measure the fractal dimension of the set of points (t, f(t)) forming the graph of a function f defined on the unit interval. First we apply it to a fractional Brownian function [1] which has a property of self-similarity for all scales, and we can get the stable and precise fractal dimension. This technique is also applied to the observational data of natural phenomena. It does not show self-similarity all over the scale but has a different self-similarity across the characteristic time scale. The present method gives us a stable characteristic time scale as well as the fractal dimension.},
	language = {en},
	number = {2},
	urldate = {2019-11-12},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Higuchi, T.},
	month = jun,
	year = {1988},
	pages = {277--283}
}

@article{wold_principal_1987,
	series = {Proceedings of the {Multivariate} {Statistical} {Workshop} for {Geologists} and {Geochemists}},
	title = {Principal component analysis},
	volume = {2},
	issn = {0169-7439},
	url = {http://www.sciencedirect.com/science/article/pii/0169743987800849},
	doi = {10.1016/0169-7439(87)80084-9},
	abstract = {Principal component analysis of a data matrix extracts the dominant patterns in the matrix in terms of a complementary set of score and loading plots. It is the responsibility of the data analyst to formulate the scientific issue at hand in terms of PC projections, PLS regressions, etc. Ask yourself, or the investigator, why the data matrix was collected, and for what purpose the experiments and measurements were made. Specify before the analysis what kinds of patterns you would expect and what you would find exciting. The results of the analysis depend on the scaling of the matrix, which therefore must be specified. Variance scaling, where each variable is scaled to unit variance, can be recommended for general use, provided that almost constant variables are left unscaled. Combining different types of variables warrants blockscaling. In the initial analysis, look for outliers and strong groupings in the plots, indicating that the data matrix perhaps should be “polished” or whether disjoint modeling is the proper course. For plotting purposes, two or three principal components are usually sufficient, but for modeling purposes the number of significant components should be properly determined, e.g. by cross-validation. Use the resulting principal components to guide your continued investigation or chemical experimentation, not as an end in itself.},
	language = {en},
	number = {1},
	urldate = {2019-11-10},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
	month = aug,
	year = {1987},
	keywords = {Reduce dimensions},
	pages = {37--52}
}

@inproceedings{wang_towards_2018,
	address = {Seoul, Republic of Korea},
	title = {Towards a {Better} {Gold} {Standard}: {Denoising} and {Modelling} {Continuous} {Emotion} {Annotations} {Based} on {Feature} {Agglomeration} and {Outlier} {Regularisation}},
	isbn = {978-1-4503-5983-2},
	shorttitle = {Towards a {Better} {Gold} {Standard}},
	url = {http://dl.acm.org/citation.cfm?doid=3266302.3266307},
	doi = {10.1145/3266302.3266307},
	abstract = {Emotions are often perceived by humans through a series of multimodal cues, such as verbal expressions, facial expressions and gestures. In order to recognise emotions automatically, reliable emotional labels are required to learn a mapping from human expressions to corresponding emotions. Dimensional emotion models have become popular and have been widely applied for annotating emotions continuously in the time domain. However, the statistical relationship between emotional dimensions is rarely studied. This paper provides a solution to automatic emotion recognition for the Audio/Visual Emotion Challenge (AVEC) 2018. The objective is to find a robust way to detect emotions using more reliable emotion annotations in the valence and arousal dimensions. The two main contributions of this paper are: 1) the proposal of a new approach capable of generating more dependable emotional ratings for both arousal and valence from multiple annotators by extracting consistent annotation features; 2) the exploration of the valence and arousal distribution using outlier detection methods, which shows a specific oblique elliptic shape. With the learned distribution, we are able to detect the prediction outliers based on their local density deviations and correct them towards the learned distribution. The proposed method performance is evaluated on the RECOLA database containing audio, video and physiological recordings. Our results show that a moving average filter is sufficient to remove the incidental errors in annotations. The unsupervised dimensionality reduction approaches could be used to determine a gold standard annotations from multiple annotations. Compared with the baseline model of AVEC 2018, our approach improved the arousal and valence prediction of concordance correlation coefficient significantly to respectively 0.821 and 0.589.},
	language = {en},
	urldate = {2019-11-10},
	booktitle = {Proceedings of the 2018 on {Audio}/{Visual} {Emotion} {Challenge} and {Workshop} - {AVEC}'18},
	publisher = {ACM Press},
	author = {Wang, Chen and Lopes, Phil and Pun, Thierry and Chanel, Guillaume},
	year = {2018},
	keywords = {Reduce dimensions},
	pages = {73--81}
}

@inproceedings{bingham_random_2001,
	address = {New York, NY, USA},
	series = {{KDD} '01},
	title = {Random {Projection} in {Dimensionality} {Reduction}: {Applications} to {Image} and {Text} {Data}},
	isbn = {978-1-58113-391-2},
	shorttitle = {Random {Projection} in {Dimensionality} {Reduction}},
	url = {http://doi.acm.org/10.1145/502512.502546},
	doi = {10.1145/502512.502546},
	abstract = {Random projections have recently emerged as a powerful method for dimensionality reduction. Theoretical results indicate that the method preserves distances quite nicely; however, empirical results are sparse. We present experimental results on using random projection as a dimensionality reduction tool in a number of cases, where the high dimensionality of the data would otherwise lead to burden-some computations. Our application areas are the processing of both noisy and noiseless images, and information retrieval in text documents. We show that projecting the data onto a random lower-dimensional subspace yields results comparable to conventional dimensionality reduction methods such as principal component analysis: the similarity of data vectors is preserved well under random projection. However, using random projections is computationally significantly less expensive than using, e.g., principal component analysis. We also show experimentally that using a sparse random matrix gives additional computational savings in random projection.},
	urldate = {2019-11-10},
	booktitle = {Proceedings of the {Seventh} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Bingham, Ella and Mannila, Heikki},
	year = {2001},
	note = {event-place: San Francisco, California},
	keywords = {Reduce dimensions},
	pages = {245--250}
}

@article{wold_principal_nodate,
	title = {Principal {Component} {Analysis}},
	language = {en},
	author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
	keywords = {Reduce dimensions},
	pages = {16}
}

@misc{kumar_understanding_2018,
	title = {Understanding {Principal} {Component} {Analysis}},
	url = {https://medium.com/@aptrishu/understanding-principle-component-analysis-e32be0253ef0},
	abstract = {The purpose of this post is to give the reader detailed understanding of Principal Component Analysis with the necessary mathematical…},
	language = {en},
	urldate = {2019-11-10},
	journal = {Medium},
	author = {Kumar, Rishav},
	month = apr,
	year = {2018},
	keywords = {Reduce dimensions}
}

@article{ringner_what_2008,
	title = {What is principal component analysis?},
	volume = {26},
	issn = {1087-0156, 1546-1696},
	url = {http://www.nature.com/articles/nbt0308-303},
	doi = {10.1038/nbt0308-303},
	language = {en},
	number = {3},
	urldate = {2019-11-10},
	journal = {Nature Biotechnology},
	author = {Ringnér, Markus},
	month = mar,
	year = {2008},
	keywords = {Reduce dimensions},
	pages = {303--304}
}

@article{fitzgibbon_removal_2007,
	title = {Removal of {EEG} {Noise} and {Artifact} {Using} {Blind} {Source} {Separation}:},
	volume = {24},
	issn = {0736-0258},
	shorttitle = {Removal of {EEG} {Noise} and {Artifact} {Using} {Blind} {Source} {Separation}},
	url = {https://insights.ovid.com/crossref?an=00004691-200706000-00002},
	doi = {10.1097/WNP.0b013e3180556926},
	abstract = {A study was performed to investigate and compare the relative performance of blind signal separation (BSS) algorithms at separating common types of contamination from EEG. The study develops a novel framework for investigating and comparing the relative performance of BSS algorithms that incorporates a realistic EEG simulation with a known mixture of known signals and an objective performance metric. The key ﬁnding is that although BSS is an effective and powerful tool for separating and removing contamination from EEG, the quality of the separation is highly dependant on the type of contamination, the degree of contamination, and the choice of BSS algorithm. BSS appears to be most effective at separating muscle and blink contamination and less effective at saccadic and tracking contamination. For all types of contamination, principal components analysis is a strong performer when the contamination is greater in amplitude than the brain signal whereas other algorithms such as second-order blind inference and Infomax are generally better for speciﬁc types of contamination of lower amplitude.},
	language = {en},
	number = {3},
	urldate = {2019-11-10},
	journal = {Journal of Clinical Neurophysiology},
	author = {Fitzgibbon, S P. and Powers, D M. W. and Pope, K J. and Clark, C R.},
	month = jun,
	year = {2007},
	keywords = {Noise reduction},
	pages = {232--243}
}

@article{shaker_eeg_2007,
	title = {{EEG} {Waves} {Classifier} using {Wavelet} {Transform} and {Fourier} {Transform}},
	volume = {1},
	abstract = {The electroencephalograph (EEG) signal is one of the most widely signal used in the bioinformatics field due to its rich information about human tasks. In this work EEG waves classification is achieved using the Discrete Wavelet Transform DWT with Fast Fourier Transform (FFT) by adopting the normalized EEG data. The DWT is used as a classifier of the EEG wave’s frequencies, while FFT is implemented to visualize the EEG waves in multi-resolution of DWT. Several real EEG data sets (real EEG data for both normal and abnormal persons) have been tested and the results improve the validity of the proposed technique.},
	language = {en},
	number = {3},
	author = {Shaker, Maan M},
	year = {2007},
	keywords = {Noise reduction},
	pages = {6}
}

@article{lang_noise_1996,
	title = {Noise reduction using an undecimated discrete wavelet transform},
	volume = {3},
	issn = {1070-9908, 1558-2361},
	url = {http://ieeexplore.ieee.org/document/475823/},
	doi = {10.1109/97.475823},
	abstract = {A new nonlinear noise reduction method is presented that uses the discrete wavelet transform. Similar to Donoho and Johnstone, we employ thresholding in the wavelet transform domain but, following a suggestion by Coifman, we use an undecimated, shift-invariant, nonorthogonal wavelet transform instead of the usual orthogonal one. This new approach can be interpreted as a repeated application of the original Donoho and Johnstone method for di erent shifts. The main feature of the new algorithm is a signi cantly improved noise reduction compared to the original wavelet based approach, both the l2 error and visually, for a large class of signals. This is shown both theoretically as well as by experimental results.},
	language = {en},
	number = {1},
	urldate = {2019-11-10},
	journal = {IEEE Signal Processing Letters},
	author = {Lang, M. and Guo, H. and Odegard, J.E. and Burrus, C.S. and Wells, R.O.},
	month = jan,
	year = {1996},
	keywords = {Noise reduction},
	pages = {10--12}
}

@misc{noauthor_multi-channel_nodate,
	title = {Multi-{Channel} {EEG} ({BCI}) {Devices}},
	url = {http://neurosky.com/2015/07/multi-channel-eeg-bci-devices/},
	abstract = {In our blog overviewing consumer EEG, we touched upon the concept that the use case dictates the complexity, cost and inconvenience of the optimal EEG system. Today, we will be looking at one important factor that affects all three of these areas when it comes to BCI devices: the number of EEG electrodes chosen to},
	language = {en-US},
	urldate = {2019-11-10}
}

@article{kaper_bci_2004,
	title = {{BCI} {Competition} 2003—{Data} {Set} {IIb}: {Support} {Vector} {Machines} for the {P}300 {Speller} {Paradigm}},
	volume = {51},
	issn = {0018-9294},
	shorttitle = {{BCI} {Competition} 2003—{Data} {Set} {IIb}},
	url = {http://ieeexplore.ieee.org/document/1300805/},
	doi = {10.1109/TBME.2004.826698},
	abstract = {We propose an approach to analyze data from the P300 speller paradigm using the machine-learning technique support vector machines. In a conservative classification scheme, we found the correct solution after five repetitions. While the classification within the competition is designed for offline analysis, our approach is also well-suited for a real-world online solution: It is fast, requires only 10 electrode positions and demands only a small amount of preprocessing.},
	language = {en},
	number = {6},
	urldate = {2019-11-10},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Kaper, M. and Meinicke, P. and Grossekathoefer, U. and Lingner, T. and Ritter, H.},
	month = jun,
	year = {2004},
	pages = {1073--1076}
}

@article{lotte_review_2007,
	title = {A review of classification algorithms for {EEG}-based brain–computer interfaces},
	volume = {4},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/4/i=2/a=R01?key=crossref.1f25f98b3df5ef0ed57b44ec26f48caa},
	doi = {10.1088/1741-2560/4/2/R01},
	abstract = {In this paper we review classiﬁcation algorithms used to design BrainComputer Interface (BCI) systems based on ElectroEncephaloGraphy (EEG). We brieﬂy present the commonly employed algorithms and describe their critical properties. Based on the literature, we compare them in terms of performance and provide guidelines to choose the suitable classiﬁcation algorithm(s) for a speciﬁc BCI.},
	language = {en},
	number = {2},
	urldate = {2019-11-10},
	journal = {Journal of Neural Engineering},
	author = {Lotte, F and Congedo, M and Lécuyer, A and Lamarche, F and Arnaldi, B},
	month = jun,
	year = {2007},
	pages = {R1--R13}
}

@article{subasi_neural_2005,
	title = {Neural {Network} {Classification} of {EEG} {Signals} by {Using} {AR} with {MLE} {Preprocessing} for {Epileptic} {Seizure} {Detection}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2297-8747/10/1/57},
	doi = {10.3390/mca10010057},
	abstract = {The purpose of the work described in this paper is to investigate the use of autoregressive (AR) model by using maximum likelihood estimation (MLE) also interpretation and performance of this method to extract classifiable features from human electroencephalogram (EEG) by using Artificial Neural Networks (ANNs). ANNs are evaluated for accuracy, specificity, and sensitivity on classification of each patient into the correct two-group categorization: epileptic seizure or non-epileptic seizure. It is observed that, ANN classification of EEG signals with AR gives better results and these results can also be used for detecting epileptic seizure.},
	language = {en},
	number = {1},
	urldate = {2019-11-09},
	journal = {Mathematical and Computational Applications},
	author = {Subasi, Abdulhamit and Kiymik, M. Kemal and Alkan, Ahmet and Koklukaya, Etem},
	month = apr,
	year = {2005},
	keywords = {Artificial Neural Networks (ANN), Autoregressive method (AR), EEG, Maximum likelihood estimation (MLE)},
	pages = {57--70}
}

@article{khawam_side_2006,
	title = {Side effects of antidepressants: an overview.},
	volume = {73},
	issn = {0891-1150, 1939-2869},
	shorttitle = {Side effects of antidepressants},
	url = {http://www.ccjm.org/cgi/doi/10.3949/ccjm.73.4.351},
	doi = {10.3949/ccjm.73.4.351},
	language = {en},
	number = {4},
	urldate = {2019-10-27},
	journal = {Cleveland Clinic Journal of Medicine},
	author = {Khawam, E. A and Laurencic, G. and Malone, D. A},
	month = apr,
	year = {2006},
	pages = {351--353}
}

@article{finnerup_review_2008,
	title = {A review of central neuropathic pain states:},
	volume = {21},
	issn = {0952-7907},
	shorttitle = {A review of central neuropathic pain states},
	url = {https://insights.ovid.com/crossref?an=00001503-200810000-00011},
	doi = {10.1097/ACO.0b013e32830a4c11},
	abstract = {Increased insight into the mechanisms of central pain will hopefully lead to increased efforts to study mechanism-based treatment of central pain.},
	language = {en},
	number = {5},
	urldate = {2019-10-27},
	journal = {Current Opinion in Anaesthesiology},
	author = {Finnerup, Nanna B},
	month = oct,
	year = {2008},
	pages = {586--589}
}

@article{al-fahoum_methods_2014,
	title = {Methods of {EEG} {Signal} {Features} {Extraction} {Using} {Linear} {Analysis} in {Frequency} and {Time}-{Frequency} {Domains}},
	volume = {2014},
	issn = {2314-4661},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4045570/},
	doi = {10.1155/2014/730218},
	abstract = {Technically, a feature represents a distinguishing property, a recognizable measurement, and a functional component obtained from a section of a pattern. Extracted features are meant to minimize the loss of important information embedded in the signal. In addition, they also simplify the amount of resources needed to describe a huge set of data accurately. This is necessary to minimize the complexity of implementation, to reduce the cost of information processing, and to cancel the potential need to compress the information. More recently, a variety of methods have been widely used to extract the features from EEG signals, among these methods are time frequency distributions (TFD), fast fourier transform (FFT), eigenvector methods (EM), wavelet transform (WT), and auto regressive method (ARM), and so on. In general, the analysis of EEG signal has been the subject of several studies, because of its ability to yield an objective mode of recording brain stimulation which is widely used in brain-computer interface researches with application in medical diagnosis and rehabilitation engineering. The purposes of this paper, therefore, shall be discussing some conventional methods of EEG feature extraction methods, comparing their performances for specific task, and finally, recommending the most suitable method for feature extraction based on performance.},
	urldate = {2019-10-13},
	journal = {ISRN Neuroscience},
	author = {Al-Fahoum, Amjed S. and Al-Fraihat, Ausilah A.},
	month = feb,
	year = {2014},
	pmid = {24967316},
	pmcid = {PMC4045570}
}

@article{klonowski_everything_2009,
	title = {Everything you wanted to ask about {EEG} but were afraid to get the right answer},
	volume = {3},
	issn = {1753-4631},
	url = {https://doi.org/10.1186/1753-4631-3-2},
	doi = {10.1186/1753-4631-3-2},
	abstract = {We answer several important questions concerning EEG. We also shortly discuss importance of nonlinear methods of contemporary physics in EEG analysis. Basic definitions and explanation of fundamental concepts may be found in my previous publications in NBP.},
	number = {1},
	urldate = {2019-10-13},
	journal = {Nonlinear Biomedical Physics},
	author = {Klonowski, Wlodzimierz},
	month = may,
	year = {2009},
	pages = {2}
}

@misc{noauthor_fourier_nodate,
	title = {Fourier {Analysis} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/neuroscience/fourier-analysis},
	urldate = {2019-10-12}
}

@article{jarjees_causality_nodate,
	title = {The {Causality} between {Electroencephalogram} ({EEG}) and {Central} {Neuropathic} {Pain} ({CNP}), and the {Effectiveness} of {Neuromodulation} {Strategies} on {Cortical} {Excitability} and {CNP} in {Patients} with {Spinal} {Cord} {Injury}},
	language = {en},
	author = {Jarjees, Mohammed Sabah},
	pages = {288}
}

@article{vuckovic_dynamic_2014,
	title = {Dynamic {Oscillatory} {Signatures} of {Central} {Neuropathic} {Pain} in {Spinal} {Cord} {Injury}},
	volume = {15},
	issn = {1526-5900, 1528-8447},
	url = {https://www.jpain.org/article/S1526-5900(14)00578-1/abstract},
	doi = {10.1016/j.jpain.2014.02.005},
	abstract = {{\textless}h2{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Central neuropathic pain (CNP) is believed to be accompanied by increased activation of the sensorimotor cortex. Our knowledge of this interaction is based mainly on functional magnetic resonance imaging studies, but there is little direct evidence on how these changes manifest in terms of dynamic neuronal activity. This study reports on the presence of transient electroencephalography (EEG)-based measures of brain activity during motor imagery in spinal cord–injured patients with CNP. We analyzed dynamic EEG responses during imaginary movements of arms and legs in 3 groups of 10 volunteers each, comprising able-bodied people, paraplegic patients with CNP (lower abdomen and legs), and paraplegic patients without CNP. Paraplegic patients with CNP had increased event-related desynchronization in the theta, alpha, and beta bands (16–24 Hz) during imagination of movement of both nonpainful (arms) and painful limbs (legs). Compared to patients with CNP, paraplegics with no pain showed a much reduced power in relaxed state and reduced event-related desynchronization during imagination of movement. Understanding these complex dynamic, frequency-specific activations in CNP in the absence of nociceptive stimuli could inform the design of interventional therapies for patients with CNP and possibly further understanding of the mechanisms involved.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Perspective{\textless}/h3{\textgreater}{\textless}p{\textgreater}This study compares the EEG activity of spinal cord–injured patients with CNP to that of spinal cord–injured patients with no pain and also to that of able-bodied people. The study shows that the presence of CNP itself leads to frequency-specific EEG signatures that could be used to monitor CNP and inform neuromodulatory treatments of this type of pain.{\textless}/p{\textgreater}},
	language = {English},
	number = {6},
	urldate = {2019-10-02},
	journal = {The Journal of Pain},
	author = {Vuckovic, Aleksandra and Hasan, Muhammad A. and Fraser, Matthew and Conway, Bernard A. and Nasseroleslami, Bahman and Allan, David B.},
	month = jun,
	year = {2014},
	pmid = {24589821},
	keywords = {main},
	pages = {645--655}
}

@article{niedermeyer_9._nodate,
	title = {9. {The} {Normal} {EEG} of the {Waking} {Adult}},
	language = {en},
	author = {Niedermeyer, Ernst},
	pages = {25}
}

@article{carlton_peripheral_2009,
	title = {Peripheral and central sensitization in remote spinal cord regions contribute to central neuropathic pain after spinal cord injury},
	volume = {147},
	issn = {0304-3959},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2787843/},
	doi = {10.1016/j.pain.2009.09.030},
	abstract = {Central neuropathic pain (CNP) developing after spinal cord injury (SCI) is described by the region affected: above-level, at-level and below-level pain occurs in dermatomes rostral, at/near, or below the SCI level, respectively. People with SCI and rodent models of SCI develop above-level pain characterized by mechanical allodynia and thermal hyperalgesia. Mechanisms underlying this pain are unknown and the goals of this study were to elucidate components contributing to the generation of above-level CNP. Following a thoracic (T10) contusion, forelimb nociceptors had enhanced spontaneous activity and were sensitized to mechanical and thermal stimulation of the forepaws 35 days post-injury. Cervical dorsal horn neurons showed enhanced responses to non-noxious and noxious mechanical stimulation as well as thermal stimulation of receptive fields. Immunostaining dorsal root ganglion (DRG) cells and cord segments with activating transcription factor 3 (ATF3, a marker for neuronal injury) ruled out neuronal damage as a cause for above-level sensitization since few C8 DRG cells expressed AFT3 and cervical cord segments had few to no ATF3-labeled cells. Finally, activated microglia and astrocytes were present in thoracic and cervical cord at 35 days post-SCI, indicating a rostral spread of glial activation from the injury site. Based on these data, we conclude that peripheral and central sensitization as well as reactive glia in the uninjured cervical cord contribute to CNP. We hypothesize that reactive glia in the cervical cord release pro-inflammatory substances which drive chronic CNP. Thus a complex cascade of events spanning many cord segments underlies above-level CNP.},
	number = {1-3},
	urldate = {2019-09-25},
	journal = {Pain},
	author = {Carlton, Susan M. and Du, Junhui and Tan, Huai Yu and Nesic, Olivera and Hargett, Gregory L. and Bopp, Anne C. and Yamani, Ammar and Lin, Qing and Willis, William D. and Hulsebosch, Claire E.},
	month = dec,
	year = {2009},
	pmid = {19853381},
	pmcid = {PMC2787843},
	pages = {265--276}
}

@article{vuckovic_prediction_2018,
	title = {Prediction of central neuropathic pain in spinal cord injury based on {EEG} classifier},
	volume = {129},
	issn = {13882457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1388245718310769},
	doi = {10.1016/j.clinph.2018.04.750},
	abstract = {Objectives: To create a classiﬁer based on electroencephalography (EEG) to identify spinal cord injured (SCI) participants at risk of developing central neuropathic pain (CNP) by comparing them with patients who had already developed pain and with able bodied controls.
Methods: Multichannel EEG was recorded in the relaxed eyes opened and eyes closed states in 10 able bodied participants and 31 subacute SCI participants (11 with CNP, 10 without NP and 10 who later developed pain within 6 months of the EEG recording). Up to nine EEG band power features were classiﬁed using linear and non-linear classiﬁers.
Results: Three classiﬁers (artiﬁcial neural networks ANN, support vector machine SVM and linear discriminant analysis LDA) achieved similar average performances, higher than 85\% on a full set of features identifying patients at risk of developing pain and achieved comparably high performance classifying between other groups. With only 10 channels, LDA and ANN achieved 86\% and 83\% accuracy respectively, identifying patients at risk of developing CNP.
Conclusion: Transferable learning classiﬁer can detect patients at risk of developing CNP. EEG markers of pain appear before its physical symptoms. Simple and complex classiﬁers have comparable performance. Signiﬁcance: Identify patients to receive prophylaxic treatment of CNP.},
	language = {en},
	number = {8},
	urldate = {2019-09-25},
	journal = {Clinical Neurophysiology},
	author = {Vuckovic, Aleksandra and Gallardo, Vicente Jose Ferrer and Jarjees, Mohammed and Fraser, Mathew and Purcell, Mariel},
	month = aug,
	year = {2018},
	pages = {1605--1617}
}

@article{hulsebosch_mechanisms_2009,
	title = {Mechanisms of {Chronic} {Central} {Neuropathic} {Pain} after {Spinal} {Cord} {Injury}},
	volume = {60},
	issn = {0165-0173},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2796975/},
	doi = {10.1016/j.brainresrev.2008.12.010},
	abstract = {Not all spinal contusions result in mechanical allodynia, in which non-noxious stimuli become noxious. The studies presented use the NYU impactor at 12.5 mm drop or the Infinite Horizons Impactor (150 kdyne, 1 sec dwell) devices to model spinal cord injury (SCI). Both of these devices and injury parameters, if done correctly, will result in animals with above level (forelimb), at level (trunk) and below level (hindlimb) mechanical allodynia that model the changes in evoked somatosensation experienced by the majority of people with SCI. The sections are as follows: 1) Mechanisms of Remote Microglial Activation and Pain Signaling in “Below-Level” Central Pain 2) Intracellular Signaling Mechanisms in Central Sensitization in “At-Level” Pain 3) Peripheral Sensitization Contributes to “Above Level” Injury Pain Following Spinal Cord Injury and 4) Role of Reactive Oxygen Species in Central Sensitization in Regional Neuropathic Pain Following SCI. To summarize, differential regional mechanisms contribute to the regional chronic pain states. We propose the importance of understanding the mechanisms in the differential regional pain syndromes after SCI in the chronic condition. Targeting regional mechanisms will be of enormous benefit to the SCI population that suffer chronic pain, and will contribute to better treatment strategies for other chronic pain syndromes.},
	number = {1},
	urldate = {2019-09-25},
	journal = {Brain research reviews},
	author = {Hulsebosch, Claire E. and Hains, Bryan C. and Crown, Eric D. and Carlton, Susan M.},
	month = apr,
	year = {2009},
	pmid = {19154757},
	pmcid = {PMC2796975},
	pages = {202--213}
}