{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import mne\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = './../../../data/raw/HV/HV1/HV1_F1_L_Removed_ICA.set'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets must have the same channels!\n",
    "channel_names = mne.io.read_epochs_eeglab(local_path).ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_channels = 3\n",
    "\n",
    "def pca(channels, n_components=5):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_result(file, name, accuracy, patients_correct, patients_total, set_name, channels, notes):\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([name, str(accuracy*100) + '%', ' ' + str(patients_correct) + '/' + str(patients_total), set_name, channels, notes])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process data sets, apply dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns relevant datasets (f.e. all right-hand recordings of healthy patients) as a list of np arrays\n",
    "def get_datasets(patient_type_location, recording_type_expression):\n",
    "    if recording_type_expression != l_new:\n",
    "        sets_locations = glob.glob(patient_type_location + recording_type_expression + suffix)\n",
    "    else:\n",
    "        sets_locations = glob.glob(patient_type_location + recording_type_expression)\n",
    "    \n",
    "    sets = []\n",
    "    for path in sets_locations: \n",
    "        epochs = mne.io.read_epochs_eeglab(path)\n",
    "        sets.append(mne.io.read_epochs_eeglab(path))\n",
    "        channel_names = epochs.ch_names\n",
    "        \n",
    "    return np.array(np.array([(patient._data) for patient in sets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './../../../'\n",
    "suffix = '*.set'\n",
    "\n",
    "location_healthy = root + 'data/raw/HV/*/'\n",
    "location_pain = root + 'data/raw/PP/*/'\n",
    "location_nopain = root + 'data/raw/PnP/*/'\n",
    "\n",
    "location_pwp = root + 'data_new/raw/PwP/*/'\n",
    "location_pdp = root + 'data_new/raw/PdP/*/'\n",
    "location_pnp = root + 'data_new/raw/PnP/*/'\n",
    "\n",
    "\n",
    "rh = '*_RH*'\n",
    "lh = '*_LH*'\n",
    "l_new = '*_L.set'   # NO SUFFIX\n",
    "l_old = '*_L_*'\n",
    "\n",
    "sets_healthy_rh = glob.glob(location_pnp + l_new)\n",
    "\n",
    "sets_healthy_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_rh_raw = get_datasets(location_pain, rh)\n",
    "pnp_rh_raw = get_datasets(location_nopain, rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_rh_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_rh_raw[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pp_rh = np.array([np.array([pca(arr) for arr in patient]) for patient in pp_rh_raw])\n",
    "pnp_rh = np.array([np.array([pca(arr) for arr in patient]) for patient in pnp_rh_raw])\n",
    "\n",
    "\n",
    "#pp_rh = pp_rh_raw\n",
    "#pnp_rh = pnp_rh_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_count = np.vstack(pp_rh).shape[0]\n",
    "pnp_count = np.vstack(pnp_rh).shape[0]\n",
    "pnp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnp_rh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some patients aside for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_and_pnp_bp = np.concatenate((pp_rh, pnp_rh))\n",
    "pp_and_pnp_bp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a pair consisting of boolean (True is test patient is PP) and test label\n",
    "def test_setup(test_index, total_size):\n",
    "    test_is_pp = test_index < len(pp_rh)\n",
    "    test_label = 1 if test_is_pp else 0\n",
    "    return test_is_pp, test_label\n",
    "\n",
    "# Splits into train and test based on the index of the test patient\n",
    "# Returns pair of test and train\n",
    "def get_train_test(data, test_index):\n",
    "    return data[test_index], np.delete(data, test_index)\n",
    "\n",
    "# Returns pair of the lengths of PP train data and respectively PNP train data\n",
    "def get_pp_pnp_length(pp_count, pnp_count, test_count, test_is_pp):\n",
    "    pp_train_len = pp_count if not test_is_pp else pp_count - test_count\n",
    "    pnp_train_len = pnp_count if test_is_pp else pnp_count - test_count\n",
    "    return pp_train_len, pnp_train_len\n",
    "\n",
    "# Ravel first dimention so that trials from all patients are treated separately; select channels\n",
    "def ravel_all_trials(data, channels):\n",
    "    return np.array(list(map(np.ravel, data[:, channels, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 4\n",
    "\n",
    "test_is_pp, test_label = test_setup(test_index, len(pp_rh))\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p, train_p = get_train_test(pp_and_pnp_bp, test_index)\n",
    "test_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p_separated = np.vstack(train_p)\n",
    "train_p_separated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "pp_train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ravel_all_trials(train_p_separated, selected_channels) * mul\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ravel_all_trials(test_p, selected_channels) * mul\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "test_labels = [test_label] * len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train, labels, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(knn.predict(test) == test_labels)/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_knn_with_xvalid(data_pp_bp, data_pnp_bp, n_neighbours, selected_channels, test_index, mul, verbose=True):\n",
    "    \n",
    "    data_bp = np.concatenate((data_pp_bp, data_pnp_bp))\n",
    "    \n",
    "    test_is_pp, test_label = test_setup(test_index, len(data_pp_bp))\n",
    "    test_p, train_p = get_train_test(data_bp, test_index)\n",
    "    train_p_separated = np.vstack(train_p)\n",
    "    pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "    \n",
    "    train = ravel_all_trials(train_p_separated, selected_channels) * mul\n",
    "    test = ravel_all_trials(test_p, selected_channels) * mul\n",
    "    \n",
    "    labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "    test_labels = [test_label] * len(test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test index', test_index, 'Preparing to classify set of', pp_train_len, 'PP and', pnp_train_len, 'PNP.')\n",
    "    \n",
    "    clas = neighbors.KNeighborsClassifier(n_neighbors=n_neighbours)\n",
    "    clas.fit(train, labels)\n",
    "    train_acc = clas.score(train, labels)\n",
    "    test_acc = clas.score(test, test_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Train score:', train_acc, '  Test score:', test_acc)\n",
    "    \n",
    "    return test_acc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_knn_with_xvalid(pp_rh, pnp_rh, 23, [0, 3, 10, 36], 2, 10000000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validate over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = 0\n",
    "patients_correct = 0\n",
    "for i in range(len(pp_and_pnp_bp)):\n",
    "    score = classify_knn_with_xvalid(pp_rh, pnp_rh, 80, [0], i, mul)\n",
    "    total_score += score\n",
    "    if score > 0.5:\n",
    "        patients_correct += 1\n",
    "    \n",
    "# TODO log acc for each patient\n",
    "    \n",
    "print(total_score/len(pp_and_pnp_bp))\n",
    "print('Correctly labeled', patients_correct, 'out of', len(pp_and_pnp_bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validate over multiple channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('all_results/pca_knn_results.csv', 'a', newline='')\n",
    "n_components = 5\n",
    "name = 'PCA + KNN'\n",
    "notes = 'k='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "previous_channels = [45, 47, 47, 51]\n",
    "k = 90\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for channel in range(61):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_knn_with_xvalid(pp_rh, pnp_rh, 19, previous_channels + [channel], i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(channel, avg_score, correct_patients)\n",
    "\n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(previous_channels + [channel]), notes + str(k) + notes_c + str(n_components))\n",
    "\n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = channel\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate over multiple n_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('all_results/pca_knn_results.csv', 'a', newline='')\n",
    "n_components = 5\n",
    "name = 'PCA + KNN'\n",
    "notes = 'k='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "channels = [45, 47, 47, 51]\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for n_neighbours in range(70, 115, 1):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_knn_with_xvalid(pp_rh, pnp_rh, n_neighbours, [channels], i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(n_neighbours, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(channels), notes + str(n_neighbours) + notes_c + str(n_components)) \n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = n_neighbours\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_svm_with_xvalid(data_pp_bp, data_pnp_bp, nu, selected_channels, test_index, mul, verbose=True):\n",
    "    \n",
    "    data_bp = np.concatenate((data_pp_bp, data_pnp_bp))\n",
    "    \n",
    "    test_is_pp, test_label = test_setup(test_index, len(data_pp_bp))\n",
    "    test_p, train_p = get_train_test(data_bp, test_index)\n",
    "    train_p_separated = np.vstack(train_p)\n",
    "    pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "    \n",
    "    train = ravel_all_trials(train_p_separated, selected_channels) * mul\n",
    "    test = ravel_all_trials(test_p, selected_channels) * mul\n",
    "    \n",
    "    #train = pca(ravel_all_trials(train_p_separated, selected_channels) * mul, n_components=pca_channels)\n",
    "    #test = pca(ravel_all_trials(test_p, selected_channels) * mul, n_components=pca_channels)\n",
    "    \n",
    "    labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "    test_labels = [test_label] * len(test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test index', test_index, 'Preparing to classify set of', pp_train_len, 'PP and', pnp_train_len, 'PNP.')\n",
    "    \n",
    "    clas = svm.NuSVC(nu=nu, kernel='linear')\n",
    "    clas.fit(train, labels)\n",
    "    train_acc = clas.score(train, labels)\n",
    "    test_acc = clas.score(test, test_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Train score:', train_acc, '  Test score:', test_acc)\n",
    "    \n",
    "    return test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = 0\n",
    "patients_correct = 0\n",
    "for i in range(len(pp_and_pnp_bp)):\n",
    "    score = classify_svm_with_xvalid(pp_rh, pnp_rh, 0.7005, [9, 9, 10, 11, 31, 33, 33, 33, 33, 39, 53, 58, 58, 58], i, mul)\n",
    "    total_score += score\n",
    "    if score > 0.5:\n",
    "        patients_correct += 1\n",
    "    \n",
    "\n",
    "print(total_score/len(pp_and_pnp_bp))\n",
    "print('Correctly labeled', patients_correct, 'out of', len(pp_and_pnp_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('all_results/pca_svm_results.csv', 'a', newline='')\n",
    "n_components = pca_channels\n",
    "name = 'PCA + SVM'\n",
    "notes = 'nu='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "previous_channels=[4]\n",
    "nu = 0.7\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for channel in range(61):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_svm_with_xvalid(pp_rh, pnp_rh, nu, previous_channels + [channel], i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(channel, avg_score, correct_patients)\n",
    "   \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(previous_channels + [channel]), notes + str(nu) + notes_c + str(n_components))\n",
    "\n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = channel\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('all_results/pca_svm_results.csv', 'a', newline='')\n",
    "n_components = pca_channels\n",
    "name = 'PCA + SVM'\n",
    "notes = 'nu='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "previous_channels=[]\n",
    "nu = 0.7005\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for channel_1 in range(61):\n",
    "    for channel_2 in range(61):\n",
    "        total_score = 0\n",
    "        correct_patients = 0\n",
    "        for i in range(len(pp_and_pnp_bp)):\n",
    "            score = classify_svm_with_xvalid(pp_rh, pnp_rh, nu, previous_channels + [channel_1, channel_2], i, mul, verbose=False)\n",
    "            total_score += score\n",
    "            if score > 0.5:\n",
    "                correct_patients += 1\n",
    "\n",
    "        avg_score = total_score/len(pp_and_pnp_bp)\n",
    "        print(channel_1, channel_2, avg_score, correct_patients)\n",
    "\n",
    "        log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(previous_channels + [channel_1, channel_2]), notes + str(nu) + notes_c + str(n_components))\n",
    "        \n",
    "        if avg_score > max_acc['value']:\n",
    "            max_acc['index'] = channel_1, channel_2\n",
    "            max_acc['value'] = avg_score\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('all_results/pca_svm_results.csv', 'a', newline='')\n",
    "n_components = pca_channels\n",
    "name = 'PCA + SVM'\n",
    "notes = 'nu='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "channels=[4]\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for nu in np.arange(0.1, 0.8, 0.01):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_svm_with_xvalid(pp_rh, pnp_rh, nu, channels, i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(nu, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(channel), notes + str(nu) + notes_c + str(n_components))\n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = nu\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
