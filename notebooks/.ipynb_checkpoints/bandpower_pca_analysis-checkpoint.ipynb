{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import mne\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "\n",
    "from utils.logger import log_result\n",
    "from utils import experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the band power over a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the band power over a time series\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    \"\"\"\n",
    "    Returns the band power over the specified frequency interval\n",
    "    \n",
    "    x - input time series (1D array)\n",
    "    fs - sampling frequency\n",
    "    fmin - min frequency\n",
    "    fmax - max frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    f, Pxx = signal.periodogram(x, fs=fs)\n",
    "    ind_min = scipy.argmax(f > fmin) - 1\n",
    "    ind_max = scipy.argmax(f > fmax) - 1\n",
    "    return scipy.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the dimensionality of an array to the specified number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(array, n_components=5):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply bandpower to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(patient_type_location, recording_type_expression):\n",
    "    \"\"\"\n",
    "    Returns relevant datasets (f.e. all right-hand recordings of patients with pain) as a list of np arrays\n",
    "    First parameter should be a regex for location, second parameter should be a regex for dataset type\n",
    "    E.g. if right-hand movement datasets of patients with pain are in /data/pp/ and their file names contain '_RH_'\n",
    "    then patient_type_location=/data/pp/ and recording_type_expression='_RH_'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find locations of matching dataset files\n",
    "    if recording_type_expression != l_new:\n",
    "        sets_locations = glob.glob(patient_type_location + recording_type_expression + suffix)\n",
    "    else:\n",
    "        # For the newer (PDP/PP) dataset we had to use a separate expression with includes the file extension\n",
    "        sets_locations = glob.glob(patient_type_location + recording_type_expression)\n",
    "    \n",
    "    sets = []\n",
    "    for path in sets_locations: \n",
    "        sets.append(mne.io.read_epochs_eeglab(path))\n",
    "        \n",
    "    return np.array(np.array([(patient._data) for patient in sets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bandpower for all channels for a patient\n",
    "bands = [(4, 8), (8, 13), (13, 30)]\n",
    "time_series_index = range(1250)[:]\n",
    "\n",
    "def channels_bandpower(channels, bands, fs=250):\n",
    "    b = bandpower\n",
    "    return np.array(list(map( lambda arr: [b(arr[time_series_index], fs, band[0], band[1]) for band in bands], channels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset locations and expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../../../data/raw/PP\\\\PP1\\\\PP1_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP10\\\\PP10_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP11\\\\PP11_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP2\\\\PP2_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP3\\\\PP3_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP4\\\\PP4_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP5\\\\PP5_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP6\\\\PP6_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP7\\\\PP7_F1_RH_Removed_ICA.set',\n",
       " './../../../data/raw/PP\\\\PP9\\\\PP9_F1_RH_Removed_ICA.set']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = './../../../'\n",
    "suffix = '*.set'\n",
    "\n",
    "# Old (PP/PNP datasets)\n",
    "location_healthy = root + 'data/raw/HV/*/'\n",
    "location_pain = root + 'data/raw/PP/*/'\n",
    "location_nopain = root + 'data/raw/PnP/*/'\n",
    "\n",
    "# New (PDP/PNP datasets)\n",
    "location_pwp = root + 'data_new/raw/PwP/*/'\n",
    "location_pdp = root + 'data_new/raw/PdP/*/'\n",
    "location_pnp = root + 'data_new/raw/PnP/*/'\n",
    "\n",
    "rh = '*_RH*'\n",
    "lh = '*_LH*'\n",
    "l_new = '*_L.set'   # NO SUFFIX\n",
    "l_old = '*_L_*'\n",
    "\n",
    "\n",
    "# As an example, get paths of all PP/PNP datasets from right-hand movements\n",
    "sets_healthy_rh = glob.glob(location_pain + rh + suffix)\n",
    "sets_healthy_rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now read the chosen datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ./../../../data/raw/PP\\PP1\\PP1_F1_RH_Removed_ICA.set...\n",
      "57 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP10\\PP10_F1_RH_Removed_ICA.set...\n",
      "57 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP11\\PP11_F1_RH_Removed_ICA.set...\n",
      "59 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP2\\PP2_F1_RH_Removed_ICA.set...\n",
      "54 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP3\\PP3_F1_RH_Removed_ICA.set...\n",
      "51 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP4\\PP4_F1_RH_Removed_ICA.set...\n",
      "58 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP5\\PP5_F1_RH_Removed_ICA.set...\n",
      "56 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP6\\PP6_F1_RH_Removed_ICA.set...\n",
      "32 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP7\\PP7_F1_RH_Removed_ICA.set...\n",
      "52 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PP\\PP9\\PP9_F1_RH_Removed_ICA.set...\n",
      "54 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP1\\PnP1_F1_RH_Removed_ICA.set...\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP2\\PnP2_F1_RH_Removed_ICA.set...\n",
      "54 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP3\\PnP3_F1_RH_Removed_ICA.set...\n",
      "44 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP4\\PnP4_F1_RH_Removed_ICA.set...\n",
      "55 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP5\\PnP5_F1_RH_Removed_ICA.set...\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP6\\PnP6_F1_RH_Removed_ICA.set...\n",
      "55 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP7\\PnP7_F01_RH_Removed_ICA.set...\n",
      "58 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP8\\PnP8_F1_RH_Removed_ICA.set...\n",
      "53 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from ./../../../data/raw/PnP\\PnP9\\PnP9_F1_RH_Removed_ICA.set...\n",
      "54 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "pp_rh_raw = get_datasets(location_pain, rh)\n",
    "pnp_rh_raw = get_datasets(location_nopain, rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 61, 1250)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The entry for a patient should have shape (n_repetitions, n_channels, n_readings)\n",
    "pp_rh_raw[4].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the bandpower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_rh_bp = np.array([np.array([channels_bandpower(repetition, bands) for repetition in patient]) for patient in pp_rh_raw])\n",
    "pnp_rh_bp = np.array([np.array([channels_bandpower(repetition, bands) for repetition in patient]) for patient in pnp_rh_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of repetitions for each class\n",
    "pp_count = np.vstack(pp_rh_bp).shape[0]\n",
    "pnp_count = np.vstack(pnp_rh_bp).shape[0]\n",
    "pnp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 61, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnp_rh_bp[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_and_pnp_bp = np.concatenate((pp_rh_bp, pnp_rh_bp))\n",
    "pp_and_pnp_bp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some patients aside for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_setup(test_index, total_size):\n",
    "    \"\"\"\n",
    "    Returns a pair consisting of boolean (True is test patient is PP) and test label\n",
    "    Labels are 1 for pain, 0 for no pain\n",
    "    \"\"\"\n",
    "    \n",
    "    test_is_pp = test_index < len(pp_rh_bp)\n",
    "    test_label = 1 if test_is_pp else 0\n",
    "    return test_is_pp, test_label\n",
    "\n",
    "\n",
    "def get_train_test(data, test_index):\n",
    "    \"\"\"\n",
    "    Splits into train and test sets based on the index of the test patient\n",
    "    Returns pair of test and train\n",
    "    \"\"\"\n",
    "    \n",
    "    return data[test_index], np.delete(data, test_index)\n",
    "\n",
    "\n",
    "def get_pp_pnp_length(pp_count, pnp_count, test_count, test_is_pp):\n",
    "    \"\"\" Returns pair of the lengths of PP train data and respectively PNP train data \"\"\"\n",
    "    \n",
    "    pp_train_len = pp_count if not test_is_pp else pp_count - test_count\n",
    "    pnp_train_len = pnp_count if test_is_pp else pnp_count - test_count\n",
    "    return pp_train_len, pnp_train_len\n",
    "\n",
    "\n",
    "def ravel_all_trials(data, channels):\n",
    "    \"\"\"\n",
    "    Ravel first dimention so that trials from all patients are treated separately; select channels\n",
    "    \"\"\"\n",
    "    return np.array(list(map(np.ravel, data[:, channels, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = 4\n",
    "\n",
    "test_is_pp, test_label = test_setup(test_index, len(pp_rh_bp))\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 61, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_p, train_p = get_train_test(pp_and_pnp_bp, test_index)\n",
    "test_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(952, 61, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_separated = np.vstack(train_p)\n",
    "train_p_separated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "pp_train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a multiplier for all features - if 1, then input data is unaltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(952, 6)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ravel_all_trials(train_p_separated, selected_channels) * mul\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ravel_all_trials(test_p, selected_channels) * mul\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the number of PCA components we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(952, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(train, n_components).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "test_labels = [test_label] * len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's time to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a simple KNN classification\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, labels, test_size=0.05)\n",
    "knn.fit(x_train, y_train)\n",
    "knn.score(x_train, y_train)\n",
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21568627450980393"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(test, [test_label]*len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21568627450980393"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(knn.predict(test) == test_labels)/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_knn_with_xvalid(data_pp_bp, data_pnp_bp, n_neighbours, selected_channels, test_index, mul, verbose=True):\n",
    "    \"\"\"\n",
    "    Leaves out patient at test_index and trains a KNN classifier on all other patients\n",
    "    Validates classifier on patient at test_index\n",
    "    Returns accuracy over all repetitions for the test patient\n",
    "    \"\"\"\n",
    "    \n",
    "    data_bp = np.concatenate((data_pp_bp, data_pnp_bp))\n",
    "    \n",
    "    test_is_pp, test_label = test_setup(test_index, len(data_pp_bp))\n",
    "    test_p, train_p = get_train_test(data_bp, test_index)\n",
    "    train_p_separated = np.vstack(train_p)\n",
    "    pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction as defined above\n",
    "    train = pca(ravel_all_trials(train_p_separated, selected_channels) * mul, n_components=n_components)\n",
    "    test = pca(ravel_all_trials(test_p, selected_channels) * mul, n_components=n_components)\n",
    "    \n",
    "    labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "    test_labels = [test_label] * len(test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test index', test_index, 'Testing on patient with', len(test), 'repetitions.')\n",
    "    \n",
    "    clas = neighbors.KNeighborsClassifier(n_neighbors=n_neighbours)\n",
    "    clas.fit(train, labels)\n",
    "    train_acc = clas.score(train, labels)\n",
    "    test_acc = clas.score(test, test_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Train score:', train_acc, '  Test score:', test_acc)\n",
    "    \n",
    "    return test_acc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test index 2 Testing on patient with 59 repetitions.\n",
      "Train score: 0.7966101694915254   Test score: 0.4406779661016949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4406779661016949"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_knn_with_xvalid(pp_rh_bp, pnp_rh_bp, 23, [0, 3, 10, 36], 2, 10000000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validate over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test index 0 Testing on patient with 57 repetitions.\n",
      "Train score: 0.7790697674418605   Test score: 0.9122807017543859\n",
      "Test index 1 Testing on patient with 57 repetitions.\n",
      "Train score: 0.7917547568710359   Test score: 0.9824561403508771\n",
      "Test index 2 Testing on patient with 59 repetitions.\n",
      "Train score: 0.7510593220338984   Test score: 0.3220338983050847\n",
      "Test index 3 Testing on patient with 54 repetitions.\n",
      "Train score: 0.7744994731296101   Test score: 0.6111111111111112\n",
      "Test index 4 Testing on patient with 51 repetitions.\n",
      "Train score: 0.7941176470588235   Test score: 1.0\n",
      "Test index 5 Testing on patient with 58 repetitions.\n",
      "Train score: 0.8021164021164021   Test score: 0.8275862068965517\n",
      "Test index 6 Testing on patient with 56 repetitions.\n",
      "Train score: 0.8046462513199577   Test score: 1.0\n",
      "Test index 7 Testing on patient with 32 repetitions.\n",
      "Train score: 0.8105046343975283   Test score: 1.0\n",
      "Test index 8 Testing on patient with 52 repetitions.\n",
      "Train score: 0.804416403785489   Test score: 0.9230769230769231\n",
      "Test index 9 Testing on patient with 54 repetitions.\n",
      "Train score: 0.78609062170706   Test score: 0.5740740740740741\n",
      "Test index 10 Testing on patient with 50 repetitions.\n",
      "Train score: 0.8027282266526757   Test score: 0.0\n",
      "Test index 11 Testing on patient with 54 repetitions.\n",
      "Train score: 0.7850368809272918   Test score: 0.0\n",
      "Test index 12 Testing on patient with 44 repetitions.\n",
      "Train score: 0.7987486965589156   Test score: 0.0\n",
      "Test index 13 Testing on patient with 55 repetitions.\n",
      "Train score: 0.7964135021097046   Test score: 0.509090909090909\n",
      "Test index 14 Testing on patient with 50 repetitions.\n",
      "Train score: 0.789087093389297   Test score: 0.0\n",
      "Test index 15 Testing on patient with 55 repetitions.\n",
      "Train score: 0.7932489451476793   Test score: 0.0\n",
      "Test index 16 Testing on patient with 58 repetitions.\n",
      "Train score: 0.7883597883597884   Test score: 0.0\n",
      "Test index 17 Testing on patient with 53 repetitions.\n",
      "Train score: 0.7989473684210526   Test score: 0.0\n",
      "Test index 18 Testing on patient with 54 repetitions.\n",
      "Train score: 0.821917808219178   Test score: 0.018518518518518517\n",
      "Overall accuracy 0.456854130693602\n",
      "Correctly labeled 10 out of 19\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "patients_correct = 0\n",
    "for i in range(len(pp_and_pnp_bp)):\n",
    "    score = classify_knn_with_xvalid(pp_rh_bp, pnp_rh_bp, 9, [5, 16, 24, 36, 60], i, mul)\n",
    "    total_score += score\n",
    "    if score > 0.5:\n",
    "        patients_correct += 1\n",
    "    \n",
    "print('Overall accuracy', total_score/len(pp_and_pnp_bp))\n",
    "print('Correctly labeled', patients_correct, 'out of', len(pp_and_pnp_bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validate over multiple channels\n",
    "\n",
    "We use this to check which channels yield better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.43420301373444276 4\n",
      "1 0.3940722792469556 6\n",
      "2 0.4839876033874894 10\n",
      "3 0.43574237659561116 9\n",
      "4 0.4175584036193553 8\n",
      "5 0.4211539121757564 8\n",
      "6 0.40926323103658424 8\n",
      "7 0.42670350660701134 8\n",
      "8 0.4898770266642892 11\n",
      "9 0.42741570612095087 8\n",
      "10 0.4269108187798073 8\n",
      "11 0.4446211972808326 8\n",
      "12 0.43944660624654075 10\n",
      "13 0.4369341860318163 9\n",
      "14 0.42801395997353064 7\n",
      "15 0.4238064229931583 8\n",
      "16 0.4348907421590404 9\n",
      "17 0.46892721052628994 11\n",
      "18 0.44173993113197807 9\n",
      "19 0.4193551351745775 9\n",
      "20 0.41678713337638557 8\n",
      "21 0.4058881813414496 7\n",
      "22 0.4222684956064862 9\n",
      "23 0.41460126184117396 8\n",
      "24 0.42073875367182284 9\n",
      "25 0.4603265204875383 5\n",
      "26 0.476384859495798 9\n",
      "27 0.4049864591960903 9\n",
      "28 0.41530172792174724 10\n",
      "29 0.4075430221114767 8\n",
      "30 0.43180377311706125 9\n",
      "31 0.448729877189854 8\n",
      "32 0.41945741447795504 7\n",
      "33 0.4410620639655514 9\n",
      "34 0.4395477580724258 8\n",
      "35 0.4291558694505733 8\n",
      "36 0.4819196244493854 9\n",
      "37 0.45269399678915423 9\n",
      "38 0.453800635610774 9\n",
      "39 0.4174689180255331 8\n",
      "40 0.4357220417069145 8\n",
      "41 0.38568047197122385 8\n",
      "42 0.41194410782698887 7\n",
      "43 0.43113072626144644 7\n",
      "44 0.4897276131152853 10\n",
      "45 0.3741735916285936 7\n",
      "46 0.42183063837015916 8\n",
      "47 0.41036240032264193 9\n",
      "48 0.40318809490982055 7\n",
      "49 0.4185107872203429 9\n",
      "50 0.404788656074211 8\n",
      "51 0.3982739244806753 9\n",
      "52 0.48415031806756526 10\n",
      "53 0.4462076072277944 9\n",
      "54 0.46003553582776524 10\n",
      "55 0.42572415255724816 8\n",
      "56 0.429148074163193 6\n",
      "57 0.42068726925547284 8\n",
      "58 0.4377958706734124 10\n",
      "59 0.4555039962975325 7\n",
      "60 0.4459556433349326 4\n",
      "Max accuracy: 8 0.4898770266642892\n"
     ]
    }
   ],
   "source": [
    "# Log results in a csv file\n",
    "file = open('all_results/test.csv', 'a', newline='')\n",
    "name = 'Bandpower + PCA + KNN'\n",
    "notes = 'freq bands 4-8,8-13,13-30, k='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "previous_channels = []\n",
    "k = 19\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for channel in range(61):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_knn_with_xvalid(pp_rh_bp, pnp_rh_bp, k, previous_channels + [channel], i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(channel, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(previous_channels + [channel]), notes + str(k) + notes_c + str(n_components))\n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = channel\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "file.close()\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate over multiple n_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5136758819146736 9\n",
      "6 0.4785311886755917 9\n",
      "11 0.48965425136444224 11\n",
      "16 0.4937298620472069 11\n",
      "21 0.49126711494484204 11\n",
      "26 0.48407435339847965 11\n",
      "31 0.4875966262529175 11\n",
      "36 0.48109807174234204 11\n",
      "41 0.4801769571049895 11\n",
      "46 0.4696324291032629 10\n",
      "51 0.4712037660398563 11\n",
      "56 0.47144413406415764 10\n",
      "61 0.4683555016129158 10\n",
      "66 0.46640973578171946 11\n",
      "71 0.46275900828654204 10\n",
      "76 0.46201038866523786 10\n",
      "81 0.4598490609795047 10\n",
      "86 0.4640143091453645 10\n",
      "91 0.46357357234919744 10\n",
      "96 0.4736341906312313 10\n",
      "Max accuracy: 1 0.5136758819146736\n"
     ]
    }
   ],
   "source": [
    "file = open('all_results/bandpower_pca_knn_results.csv', 'a', newline='')\n",
    "name = 'Bandpower + PCA + KNN'\n",
    "notes = 'freq bands 4-8,8-13,13-30, k='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "channels = [8]\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for n_neighbours in range(1, 100, 5):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_knn_with_xvalid(pp_rh_bp, pnp_rh_bp, n_neighbours, channels, i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(n_neighbours, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(channels), notes + str(n_neighbours) + notes_c + str(n_components))\n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = n_neighbours\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "file.close()\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nusvm_with_xvalid(data_pp_bp, data_pnp_bp, nu, selected_channels, test_index, mul, verbose=True):\n",
    "    \"\"\"\n",
    "    Leaves out patient at test_index and trains a linear SVM classifier on all other patients\n",
    "    Validates classifier on patient at test_index\n",
    "    Returns accuracy over all repetitions for the test patient\n",
    "    \"\"\"\n",
    "    \n",
    "    data_bp = np.concatenate((data_pp_bp, data_pnp_bp))\n",
    "    \n",
    "    test_is_pp, test_label = test_setup(test_index, len(data_pp_bp))\n",
    "    test_p, train_p = get_train_test(data_bp, test_index)\n",
    "    train_p_separated = np.vstack(train_p)\n",
    "    pp_train_len, pnp_train_len = get_pp_pnp_length(pp_count, pnp_count, len(test_p), test_is_pp)\n",
    "    \n",
    "    train = pca(ravel_all_trials(train_p_separated, selected_channels) * mul, n_components=pca_components)\n",
    "    test = pca(ravel_all_trials(test_p, selected_channels) * mul, n_components=pca_components)\n",
    "    \n",
    "    labels = [1] * pp_train_len + [0] * pnp_train_len\n",
    "    test_labels = [test_label] * len(test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test index', test_index, 'Preparing to classify set of', pp_train_len, 'PP and', pnp_train_len, 'PNP.')\n",
    "    \n",
    "    clas = svm.NuSVC(nu=nu, kernel='linear')\n",
    "    clas.fit(train, labels)\n",
    "    train_acc = clas.score(train, labels)\n",
    "    test_acc = clas.score(test, test_labels)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Train score:', train_acc, '  Test score:', test_acc)\n",
    "    \n",
    "    return test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test index 0 Preparing to classify set of 473 PP and 473 PNP.\n",
      "Train score: 0.6807610993657506   Test score: 0.9649122807017544\n",
      "Test index 1 Preparing to classify set of 473 PP and 473 PNP.\n",
      "Train score: 0.7071881606765328   Test score: 1.0\n",
      "Test index 2 Preparing to classify set of 471 PP and 473 PNP.\n",
      "Train score: 0.6917372881355932   Test score: 0.5254237288135594\n",
      "Test index 3 Preparing to classify set of 476 PP and 473 PNP.\n",
      "Train score: 0.6891464699683878   Test score: 0.9814814814814815\n",
      "Test index 4 Preparing to classify set of 479 PP and 473 PNP.\n",
      "Train score: 0.7121848739495799   Test score: 1.0\n",
      "Test index 5 Preparing to classify set of 472 PP and 473 PNP.\n",
      "Train score: 0.6835978835978836   Test score: 0.9827586206896551\n",
      "Test index 6 Preparing to classify set of 474 PP and 473 PNP.\n",
      "Train score: 0.7286166842661035   Test score: 1.0\n",
      "Test index 7 Preparing to classify set of 498 PP and 473 PNP.\n",
      "Train score: 0.713697219361483   Test score: 1.0\n",
      "Test index 8 Preparing to classify set of 478 PP and 473 PNP.\n",
      "Train score: 0.5793901156677181   Test score: 1.0\n",
      "Test index 9 Preparing to classify set of 476 PP and 473 PNP.\n",
      "Train score: 0.5563751317175974   Test score: 0.7962962962962963\n",
      "Test index 10 Preparing to classify set of 480 PP and 473 PNP.\n",
      "Train score: 0.5550891920251836   Test score: 1.0\n",
      "Test index 11 Preparing to classify set of 476 PP and 473 PNP.\n",
      "Train score: 0.4320337197049526   Test score: 0.0\n",
      "Test index 12 Preparing to classify set of 486 PP and 473 PNP.\n",
      "Train score: 0.5224191866527633   Test score: 1.0\n",
      "Test index 13 Preparing to classify set of 475 PP and 473 PNP.\n",
      "Train score: 0.46729957805907174   Test score: 0.0\n",
      "Test index 14 Preparing to classify set of 480 PP and 473 PNP.\n",
      "Train score: 0.5561385099685204   Test score: 1.0\n",
      "Test index 15 Preparing to classify set of 475 PP and 473 PNP.\n",
      "Train score: 0.48417721518987344   Test score: 0.0\n",
      "Test index 16 Preparing to classify set of 472 PP and 473 PNP.\n",
      "Train score: 0.5238095238095238   Test score: 1.0\n",
      "Test index 17 Preparing to classify set of 477 PP and 473 PNP.\n",
      "Train score: 0.4431578947368421   Test score: 0.0\n",
      "Test index 18 Preparing to classify set of 476 PP and 473 PNP.\n",
      "Train score: 0.40990516332982085   Test score: 0.0\n",
      "0.6974143372622498\n",
      "Correctly labeled 14 out of 19\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "patients_correct = 0\n",
    "for i in range(len(pp_and_pnp_bp)):\n",
    "    score = experiments.classify_nusvm_with_xvalid(pp_rh_bp, pnp_rh_bp, 0.8585, [0, 1, 1, 2, 3, 3, 5, 12, 13, 23, 30, 52, 57], i, pca_components=3)\n",
    "    total_score += score\n",
    "    if score > 0.5:\n",
    "        patients_correct += 1\n",
    "    \n",
    "\n",
    "print(total_score/len(pp_and_pnp_bp))\n",
    "print('Correctly labeled', patients_correct, 'out of', len(pp_and_pnp_bp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8583186562669167 16\n",
      "1 0.8563693385281255 16\n",
      "2 0.8583186562669167 16\n",
      "3 0.8525456768097268 16\n",
      "4 0.8428976586317629 16\n",
      "5 0.9081838305745531 17\n",
      "6 0.9091113333753832 17\n",
      "7 0.9109502352142852 17\n",
      "8 0.8427616012361775 16\n",
      "9 0.853512579773 16\n",
      "10 0.8583936300261009 16\n",
      "11 0.8583561431465089 16\n",
      "12 0.8613176066342881 16\n",
      "13 0.908026258606098 17\n",
      "14 0.8564443122873096 16\n",
      "15 0.9080637454856901 17\n",
      "16 0.8535203356791226 16\n",
      "17 0.8476348955831562 16\n",
      "18 0.9128245791938924 17\n",
      "19 0.9079887717265058 17\n",
      "20 0.8612426328751038 16\n",
      "21 0.8992489135895577 17\n",
      "22 0.8401706585363418 16\n",
      "23 0.9038950774008757 17\n",
      "24 0.8442425423138455 16\n",
      "25 0.9067891915795573 17\n",
      "26 0.844710918974969 16\n",
      "27 0.8514055586097173 16\n",
      "28 0.8544794827362733 16\n",
      "29 0.8533329012811618 16\n",
      "30 0.8584530919730403 16\n",
      "31 0.9089259437163094 17\n",
      "32 0.8564894236169882 16\n",
      "33 0.9099558105356501 17\n",
      "34 0.8515710179403311 16\n",
      "35 0.9080637454856901 17\n",
      "36 0.9119700054133596 17\n",
      "37 0.9000040663733795 17\n",
      "38 0.8563394760986196 16\n",
      "39 0.889342280756966 17\n",
      "40 0.8502017244657744 16\n",
      "41 0.8851207454363504 17\n",
      "42 0.8524729123086502 16\n",
      "43 0.8477240885035651 16\n",
      "44 0.8475818968913188 16\n",
      "45 0.9049743095468896 17\n",
      "46 0.854404508977089 16\n",
      "47 0.9078388242081372 17\n",
      "48 0.9041276231285152 17\n",
      "49 0.9118499203244966 17\n",
      "50 0.9080559895795678 17\n",
      "51 0.908813483077533 17\n",
      "52 0.8661909009812668 16\n",
      "53 0.9009555889804437 17\n",
      "54 0.8475974087035638 16\n",
      "55 0.8499643841779866 16\n",
      "56 0.8518542399698388 16\n",
      "57 0.8595027246016201 16\n",
      "58 0.8529787149015672 16\n",
      "59 0.860372678738362 16\n",
      "60 0.8573814842771131 16\n",
      "Max accuracy: 18 0.9128245791938924\n"
     ]
    }
   ],
   "source": [
    "file = open('all_results/bandpower_pca_svm_results.csv', 'a', newline='')\n",
    "n_components = pca_components\n",
    "name = 'Bandpower + PCA + SVM'\n",
    "notes = 'freq bands 4-8,8-13,13-30 over 375-500, nu='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "previous_channels=[11, 36, 52]\n",
    "nu = 0.8\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for channel in range(61):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_nusvm_with_xvalid(pp_rh_bp, pnp_rh_bp, nu, previous_channels + [channel], i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(channel, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(previous_channels + [channel]), notes + str(nu) + notes_c + str(n_components))\n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = channel\n",
    "        max_acc['value'] = avg_score\n",
    "        \n",
    "\n",
    "file.close()\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validate over multiple nu values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.5403312814798864 10\n",
      "0.51 0.5924661918483872 11\n",
      "0.52 0.48607394191693915 9\n",
      "0.53 0.43051838636138373 8\n",
      "0.54 0.49289655400270926 9\n",
      "0.55 0.5416294974724948 10\n",
      "0.56 0.8135593220338982 15\n",
      "0.5700000000000001 0.6498166319754187 12\n",
      "0.5800000000000001 0.7562083422452454 14\n",
      "0.5900000000000001 0.47962744762345955 10\n",
      "0.6000000000000001 0.44026497505534073 8\n",
      "0.6100000000000001 0.4392903161859451 8\n",
      "0.6200000000000001 0.4265447771246165 8\n",
      "0.6300000000000001 0.39638387411052795 8\n",
      "0.6400000000000001 0.49090974938432563 9\n",
      "0.6500000000000001 0.4841246241781478 9\n",
      "0.6600000000000001 0.22584002378828427 4\n",
      "0.6700000000000002 0.1698042593333128 4\n",
      "0.6800000000000002 0.3176447565386013 7\n",
      "0.6900000000000002 0.23907225691347014 5\n",
      "0.7000000000000002 0.2905481689156979 6\n",
      "0.7100000000000002 0.34238609706941553 7\n",
      "0.7200000000000002 0.39696699375557537 8\n",
      "0.7300000000000002 0.34433541480820695 7\n",
      "0.7400000000000002 0.11821455710840188 3\n",
      "0.7500000000000002 0.19007044203143744 4\n",
      "0.7600000000000002 0.30242508342419133 6\n",
      "0.7700000000000002 0.5548617305976806 11\n",
      "0.7800000000000002 0.8624126465678035 16\n",
      "0.7900000000000003 0.704763941770374 12\n",
      "0.8000000000000003 0.9178478210592395 17\n",
      "0.8100000000000003 0.7723979526511133 14\n",
      "0.8200000000000003 0.748507144175459 13\n",
      "0.8300000000000003 0.9064880038917997 17\n",
      "0.8400000000000003 0.8537219892383078 16\n",
      "0.8500000000000003 0.8897843674059491 17\n",
      "0.8600000000000003 0.8052471623242794 15\n",
      "0.8700000000000003 0.9159162243908008 17\n",
      "Max accuracy: 0.8000000000000003 0.9178478210592395\n"
     ]
    }
   ],
   "source": [
    "file = open('all_results/bandpower_pca_svm_results.csv', 'a', newline='')\n",
    "n_components = pca_components\n",
    "name = 'Bandpower + PCA + SVM'\n",
    "notes = 'freq bands 4-8,8-13,13-30 over 375-500 nu='\n",
    "notes_c = ', n_components='\n",
    "\n",
    "channels = [11, 36, 52]\n",
    "\n",
    "max_acc = {'index': 0, 'value': 0}\n",
    "for param in np.arange(0.5, 0.875, 0.01):    \n",
    "    total_score = 0\n",
    "    correct_patients = 0\n",
    "    for i in range(len(pp_and_pnp_bp)):\n",
    "        score = classify_nusvm_with_xvalid(pp_rh_bp, pnp_rh_bp, param, channels, i, mul, verbose=False)\n",
    "        total_score += score\n",
    "        if score > 0.5:\n",
    "            correct_patients += 1\n",
    "        \n",
    "    avg_score = total_score/len(pp_and_pnp_bp)\n",
    "    print(param, avg_score, correct_patients)\n",
    "    \n",
    "    log_result(file, name, avg_score, correct_patients, len(pp_and_pnp_bp), 'RH', str(channels), notes + str(param) + notes_c + str(n_components))\n",
    "    \n",
    "    if avg_score > max_acc['value']:\n",
    "        max_acc['index'] = param\n",
    "        max_acc['value'] = avg_score\n",
    "\n",
    "file.close()\n",
    "        \n",
    "print('Max accuracy:', max_acc['index'], max_acc['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
